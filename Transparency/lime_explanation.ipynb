{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..') # append the parent directory of Transparency to python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "from collections import namedtuple\n",
    "from Transparency.common_code.common import get_latest_model\n",
    "from Transparency.configurations import configurations\n",
    "from Transparency.Trainers.DatasetBC import datasets\n",
    "from Transparency.model import Binary_Classification as BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MockArgs = namedtuple(\n",
    "    \"MockArgs\",\n",
    "    [\n",
    "        \"dataset\",\n",
    "        \"encoder\",\n",
    "        \"data_dir\",\n",
    "        \"output_dir\",\n",
    "        \"attention\",\n",
    "        \"diversity\",\n",
    "#         \"seed\",\n",
    "#         \"job_type\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = MockArgs(dataset='sst',\n",
    "                encoder='vanilla_lstm',\n",
    "                data_dir='.',\n",
    "                output_dir='../test_seeds',\n",
    "                attention='tanh',\n",
    "                diversity=0,\n",
    "#                 seed=0,\n",
    "#                 job_type='both'\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets[args.dataset](args)\n",
    "config = configurations[args.encoder](dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_model_name = get_latest_model(\n",
    "    os.path.join(config[\"training\"][\"basepath\"], config[\"training\"][\"exp_dirname\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../test_seeds/sst/lstm+tanh/Tue_Jan_12_18:18:11_2021'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder params {'vocab_size': 13826, 'embed_size': 300, 'type': 'vanillalstm', 'hidden_size': 128, 'pre_embed': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-15 12:32:42,222 - instantiating class <class 'Transparency.model.modules.Encoder.Encoder'> from params {'vocab_size': 13826, 'embed_size': 300, 'type': 'vanillalstm', 'hidden_size': 128, 'pre_embed': None} and extras set()\n",
      "INFO - 2021-01-15 12:32:42,224 - type = vanillalstm\n",
      "INFO - 2021-01-15 12:32:42,225 - instantiating class <class 'Transparency.model.modules.Encoder.EncoderorthoRNN'> from params {'vocab_size': 13826, 'embed_size': 300, 'hidden_size': 128, 'pre_embed': None} and extras set()\n",
      "INFO - 2021-01-15 12:32:42,227 - vocab_size = 13826\n",
      "INFO - 2021-01-15 12:32:42,227 - embed_size = 300\n",
      "INFO - 2021-01-15 12:32:42,228 - hidden_size = 128\n",
      "INFO - 2021-01-15 12:32:42,228 - pre_embed = None\n",
      "INFO - 2021-01-15 12:32:42,367 - instantiating class <class 'Transparency.model.modules.Decoder.AttnDecoder'> from params {'attention': {'type': 'tanh'}, 'output_size': 1, 'hidden_size': 256} and extras set()\n",
      "INFO - 2021-01-15 12:32:42,368 - hidden_size = 256\n",
      "INFO - 2021-01-15 12:32:42,369 - output_size = 1\n",
      "INFO - 2021-01-15 12:32:42,370 - use_attention = True\n",
      "INFO - 2021-01-15 12:32:42,374 - regularizer_attention = None\n",
      "INFO - 2021-01-15 12:32:42,374 - instantiating class <class 'Transparency.model.modules.Attention.Attention'> from params <allennlp.common.params.Params object at 0x7f701a11e160> and extras set()\n",
      "INFO - 2021-01-15 12:32:42,375 - attention.type = tanh\n",
      "INFO - 2021-01-15 12:32:42,380 - type = tanh\n",
      "INFO - 2021-01-15 12:32:42,381 - instantiating class <class 'Transparency.model.modules.Attention.TanhAttention'> from params <allennlp.common.params.Params object at 0x7f701a11e160> and extras set()\n",
      "INFO - 2021-01-15 12:32:42,382 - attention.hidden_size = 256\n",
      "INFO - 2021-01-15 12:32:42,383 - hidden_size = 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config  {'model': {'encoder': {}, 'decoder': {}, 'generator': {'hidden_size': 256, 'sparsity_lambda': 0.2}}, 'training': {'bsize': 32, 'weight_decay': 1e-05, 'pos_weight': [0.9135802469135803], 'basepath': '../test_seeds', 'exp_dirname': 'sst/lstm+tanh'}}\n",
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "model = BC.Model.init_from_config(latest_model_name, load_gen=False)\n",
    "model.dirname = latest_model_name      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, attentions, conicity_values = model.evaluate(dataset.test_data.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47334918, 0.8559502 , 0.9091199 , ..., 0.8185079 , 0.7020547 ,\n",
       "       0.33219284], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conicity_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_proba(data):\n",
    "    # TODO should have text here as first step\n",
    "    predictions, _, _ = model.evaluate(dataset, data)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use lime for explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['0', '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yun/.pyenv/versions/3.6.5/envs/fact/lib/python3.6/site-packages/lime/lime_text.py:114: FutureWarning: split() requires a non-empty pattern match.\n",
      "  self.as_list = [s for s in splitter.split(self.raw) if s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-3b7b89857534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m83\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/fact/lib/python3.6/site-packages/lime/lime_text.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    409\u001b[0m                           IndexedString(text_instance, bow=self.bow,\n\u001b[1;32m    410\u001b[0m                                         \u001b[0msplit_expression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_expression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m                                         mask_string=self.mask_string))\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0mdomain_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextDomainMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         data, yss, distances = self.__data_labels_distances(\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/fact/lib/python3.6/site-packages/lime/lime_text.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, raw_string, split_expression, bow, mask_string)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# the separator character from the split results.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0msplitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(%s)|$'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msplit_expression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mnon_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "idx = 83\n",
    "exp = explainer.explain_instance([dataset.test_data.X[idx]], predict_proba, num_features=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
